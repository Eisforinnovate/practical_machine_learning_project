}
add2(3,5)
}
add2 <- function(x,y){
x+y
}
add2(3.5)
add2(3,4)
above <-function(x,n){
use <- x>n
x[use]
}
x<-1:20
above(x,12)
columnmean<- function(y){
ne<-ncol (y)
means<- numeric(nc)
for (i in 1:nc){
means[i]<- mean(y[,1])
}
means
}
make.power<-function(n){pow<-function(x){x^n}pow}
cube <- make.power(3)
lexical scoping.R
pow
}
cube <-make.power(3)
cube <-make.power(3)
x^3
}
{
x^3
}
cube(3)
cube(3)
}
z<-10
f(3)
f(3)
z<-10
f(3)
z<-10
f(3)
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z<-10 f(3)
z<-10
f(3)
library(datasets)
data(iris)
?iris
librar(datasets)
library(datasets)
data(mtcars)
?mtcars
inv<- NULL
}
x = rbind(c(1, -1/4), c(-1/4, 1))
m = makeCacheMatrix(x)
makeCacheMatrix <- function(x = matrix()) {
#store cache of inverse matrix
inv<- NULL
#1. set value of the matrix
set<-function(y){
x<<-y
invCache<<-NULL
}
#2.get value for matrix
get <- function() x
setinverse <- function(inverse) inv <<- inverse
getinverse <- function() inv
list(set=set, get=get, setinverse=setinverse, getinverse=getinverse)
}
## This function computes the inverse of the special "matrix" returned by makeCacheMatrix above.
##If the inverse has already been calculated (and the matrix has not changed), then the cachesolve
##should retrieve the inverse from the cache.
cacheSolve <- function(x, ...) {
inv <- x$getinverse()
if(!is.null(inv)) {
message("just a sec, retreiving cached data.")
return(inv)
}
data <- x$get()
## Put comments here that give an overall description of what your
## functions do
clear
install.packages("swirl")
library(swirl)
swirl()
swirl()
5 + 7
x <- 5 + 7
x
y <- x-3
y
z<-c(1.1,9, 3.14)
?
z<-c(1.1,9, 3.14)
?c
z
```
xyplot(weight ~ Time | Diet, BodyWeight)
library(httr)
require(httpuv)
require(jsonlite)
```{r}
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
f <- file.path(getwd(), "ss06pid.csv")
download.file(url, f)
acs <- data.table(read.csv(f))
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
query2 <- sqldf("select pwgtp1 from acs")  ## NO
query3 <- sqldf("select * from acs where AGEP < 50 and pwgtp1")  ## NO
query4 <- sqldf("select * from acs where AGEP < 50")  ## NO
identical(query3, query4)
```
```
```{r}
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
f <- file.path(getwd(), "ss06pid.csv")
download.file(url, f)
acs <- data.table(read.csv(f))
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
query2 <- sqldf("select pwgtp1 from acs")  ## NO
query3 <- sqldf("select * from acs where AGEP < 50 and pwgtp1")  ## NO
query4 <- sqldf("select * from acs where AGEP < 50")  ## NO
identical(query3, query4)
```
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
f <- file.path(getwd(), "ss06pid.csv")
download.file(url, f)
acs <- data.table(read.csv(f))
acs <- data.table(read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"))
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
f <- file.path(getwd(), "ss06pid.csv")
download.file(url, f)
oauth_endpoints("github")
myapp <- oauth_app("quiz2", "ddb0d599de51ccd02f4b", secret = "6af1109f6ecf442d292425087d49bb13d9bbe9c8")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
load("data/samsungData.rda")
library(kernlab); data(spam); set.seed(333)
library(caret)
library(caret)
dim(training)
library(caret); library(kernlab); data(spam)
inTrains <-createDataPartition(y=spam$type,p=0.75,list=FALSE)
training <- spam[inTrain,]
testing <-spam[-inTrain,]
dim(training)
library(AppliedPredictiveModeling)
library(caret)
library(caret)
install.packages("forecast")Installing package(s) into â€˜C:/Program Files/R/R-2.15.2/libraryâ€™
install.packages("caret", dependencies = c("Depends", "Suggests"))
install.packages("AppliedPredictiveModeling")
install.packages("caret")
library(caret)
install.packages("lattice")
install.packages("lattice")
install.packages("ggplot2")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
clear
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
pbiom(8,10,0.5,lower.tail=FALSE)
pbinom(8, 10, 0.5, lower.tail = FALSE)
ppois(40,lambda=2.5*4)
ppois(40,lambda=9*4)
ppois(40, 9 * 5) = 26%
ppois(40, 9 * 5)
n <- 100
means <- cumsum(rnorm(n))/(1:n)
means
n <- 10000
means <- cumsum(rnorm(n))/(1:n)
library (ggplot2)
g <- ggplot(data.frame(x = 1:n), y=means), aes(x=x,y=y)
round(pnorm(70,mean=80,sd=10)*100)
round(pnorm(95,mean=1100,sd=10))
round(qnorm(95,mean=1100,sd=10))
round(pnorm(14, mean=15,sd=10)*100)
round(pnorm(15, mean=15,sd=10)*100)
round(pnorm(16, mean=15,sd=10)*100)
round(pnorm(10, mean=5)*100)
round(qnorm(0.95, mean = 1100, sd = 75))
clear
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
set.seed(3433)
library(caret)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.9)
preProc$rotation
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain, ]
testing = adData[-inTrain, ]
set.seed(3433)
IL_str <- grep("^IL", colnames(training), value = TRUE)
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
install.packages("rmongodb")
library("rmongodb", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
detach("package:rmongodb", unload=TRUE)
library("rmongodb", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
detach("package:rmongodb", unload=TRUE)
library("rmongodb", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
detach("package:rmongodb", unload=TRUE)
install.packages(c("caret", "class", "httr", "MASS", "Matrix", "mgcv", "RCurl", "swirl"))
load("~/.RData")
install.packages("HadoopStreaming")
install.packages("NLP")
8^2
sin(30*pi/180)
f+25
f
f<-
25
f <-
25
w<- .Last.value
w
b <-6
b<-b+5
b
install.packages("bigdata")
l <- 80 +
30
l
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
names(segmentationOrigina)
names(segmentationOriginal)
table(segmentationOriginal$Case)
library(pgmm)
library(pgmm)
install.packages("library(pgmm)")
library(pgmm)
install.packages("library(pgmm)")
install.packages("library(ElmStatLearn)")
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
testError <- function(pred, data, outcome) {
sum(predict(pred, data) != outcome)/length(outcome)
}
vowelTree <- randomForest(y ~ ., data = vowel.train, prox = TRUE)
print("Test error random forest:")
library("knitr", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install.packages("e1071")
library("e1071", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library("class", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library("lattice", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library("randomForest", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
setwd("~/Desktop/practical_machine)learning_project")
answers = rep("A", 20)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
answers = rep("A", 20)
answers = rep("B", 20)
answers = rep("C", 20)
answers = rep("D", 20)
setwd("~/Desktop/practical_machine)learning_project")
answers = rep("B", 20)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
answers = rep("C", 20)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
answers = rep("D", 20)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
answers = rep("E", 20)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
